# AI & Êú∫Âô®‰∫∫ ÊäÄÊúØÁÉ≠ÁÇπÊó•Êä•Ôºà2026-02-07 03:39 UTCÔºâ


> Êù•Ê∫êÂåÖÂê´ÔºöarXivÔºàcs.AI/cs.ROÔºâ„ÄÅOpenAI/DeepMind/Google/Meta/NVIDIA„ÄÅIEEE Spectrum Robotics„ÄÅThe Robot Report Á≠âÂÆòÊñπ/Â™í‰Ωì RSSÔºå‰ª•ÂèäÊåâÂÖ≥ÈîÆËØç/Topic ËøáÊª§ÁöÑ GitHub Trending„ÄÇ


## üì° ÊúÄÊñ∞ËµÑËÆØÔºàRSS ËÅöÂêàÔºâ

| Êó∂Èó¥(UTC) | Ê†áÈ¢ò | Êù•Ê∫ê |

|---|---|---|

| 2026-02-06 21:36 | [Robot development, from actuators to AI](https://www.therobotreport.com/robot-development-from-actuators-ai-mauerer/) | www.therobotreport.com |
| 2026-02-06 21:00 | [How ADR and Intel went underground with edge AI](https://www.therobotreport.com/how-adr-intel-go-underground-edge-ai/) | www.therobotreport.com |
| 2026-02-06 13:32 | [Bills introduced to strengthen U.S. robotics competitiveness, humanoid security](https://www.therobotreport.com/bills-introduced-strengthen-u-s-robotics-competitiveness-humanoid-security/) | www.therobotreport.com |
| 2026-02-06 10:00 | [Korea privacy policy](https://openai.com/policies/kr-privacy-policy) | openai.com |
| 2026-02-06 10:00 | [Making AI work for everyone, everywhere: our approach to localization](https://openai.com/index/our-approach-to-localization) | openai.com |
| 2026-02-06 05:00 | [Knowledge Model Prompting Increases LLM Performance on Planning Tasks](https://arxiv.org/abs/2602.03900) | export.arxiv.org |
| 2026-02-06 05:00 | [Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation](https://arxiv.org/abs/2602.03950) | export.arxiv.org |
| 2026-02-06 05:00 | [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955) | export.arxiv.org |
| 2026-02-06 05:00 | [Active Epistemic Control for Query-Efficient Verified Planning](https://arxiv.org/abs/2602.03974) | export.arxiv.org |
| 2026-02-06 05:00 | [Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure](https://arxiv.org/abs/2602.03975) | export.arxiv.org |
| 2026-02-06 05:00 | [Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning](https://arxiv.org/abs/2602.03978) | export.arxiv.org |
| 2026-02-06 05:00 | [When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making](https://arxiv.org/abs/2602.04003) | export.arxiv.org |
| 2026-02-06 05:00 | [Axiomatic Foundations of Counterfactual Explanations](https://arxiv.org/abs/2602.04028) | export.arxiv.org |
| 2026-02-06 05:00 | [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089) | export.arxiv.org |
| 2026-02-06 05:00 | [Interfaze: The Future of AI is built on Task-Specific Small Models](https://arxiv.org/abs/2602.04101) | export.arxiv.org |
| 2026-02-06 05:00 | [OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows](https://arxiv.org/abs/2602.04144) | export.arxiv.org |
| 2026-02-06 05:00 | [Steering LLMs via Scalable Interactive Oversight](https://arxiv.org/abs/2602.04210) | export.arxiv.org |
| 2026-02-06 05:00 | [InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons](https://arxiv.org/abs/2602.04213) | export.arxiv.org |
| 2026-02-06 05:00 | [Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search](https://arxiv.org/abs/2602.04248) | export.arxiv.org |
| 2026-02-06 05:00 | [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284) | export.arxiv.org |
| 2026-02-06 05:00 | [From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents](https://arxiv.org/abs/2602.04326) | export.arxiv.org |
| 2026-02-06 05:00 | [Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications](https://arxiv.org/abs/2602.04385) | export.arxiv.org |
| 2026-02-06 05:00 | [ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control](https://arxiv.org/abs/2602.04496) | export.arxiv.org |
| 2026-02-06 05:00 | [From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums](https://arxiv.org/abs/2602.04572) | export.arxiv.org |
| 2026-02-06 05:00 | [Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration](https://arxiv.org/abs/2602.04575) | export.arxiv.org |
| 2026-02-06 05:00 | [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634) | export.arxiv.org |
| 2026-02-06 05:00 | [Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents](https://arxiv.org/abs/2602.04813) | export.arxiv.org |
| 2026-02-06 05:00 | [Are AI Capabilities Increasing Exponentially? A Competing Hypothesis](https://arxiv.org/abs/2602.04836) | export.arxiv.org |
| 2026-02-06 05:00 | [Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing](https://arxiv.org/abs/2602.04837) | export.arxiv.org |
| 2026-02-06 05:00 | [Fluid Representations in Reasoning Models](https://arxiv.org/abs/2602.04843) | export.arxiv.org |
| 2026-02-06 05:00 | [Merged ChemProt-DrugProt for Relation Extraction from Biomedical Literature](https://arxiv.org/abs/2405.18605) | export.arxiv.org |
| 2026-02-06 05:00 | [HybridQuestion: Human-AI Collaboration for Identifying High-Impact Research Questions](https://arxiv.org/abs/2602.03849) | export.arxiv.org |
| 2026-02-06 05:00 | [WebAccessVL: Making an Accessible Web via Violation-Conditioned VLM](https://arxiv.org/abs/2602.03850) | export.arxiv.org |
| 2026-02-06 05:00 | [Perceptions of AI-CBT: Trust and Barriers in Chinese Postgrads](https://arxiv.org/abs/2602.03852) | export.arxiv.org |
| 2026-02-06 05:00 | [PaperX: A Unified Framework for Multimodal Academic Presentation Generation with Scholar DAG](https://arxiv.org/abs/2602.03866) | export.arxiv.org |
| 2026-02-06 05:00 | [Benchmarking Automatic Speech Recognition for Indian Languages in Agricultural Contexts](https://arxiv.org/abs/2602.03868) | export.arxiv.org |
| 2026-02-06 05:00 | [Understanding the Impact of Differentially Private Training on Memorization of Long-Tailed Data](https://arxiv.org/abs/2602.03872) | export.arxiv.org |
| 2026-02-06 05:00 | [Decoding Ambiguous Emotions with Test-Time Scaling in Audio-Language Models](https://arxiv.org/abs/2602.03873) | export.arxiv.org |
| 2026-02-06 05:00 | [Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra](https://arxiv.org/abs/2602.03875) | export.arxiv.org |
| 2026-02-06 05:00 | [GOPO: Policy Optimization using Ranked Rewards](https://arxiv.org/abs/2602.03876) | export.arxiv.org |
| 2026-02-06 05:00 | [TruKAN: Towards More Efficient Kolmogorov-Arnold Networks Using Truncated Power Functions](https://arxiv.org/abs/2602.03879) | export.arxiv.org |
| 2026-02-06 05:00 | [DiGAN: Diffusion-Guided Attention Network for Early Alzheimer's Disease Detection](https://arxiv.org/abs/2602.03881) | export.arxiv.org |
| 2026-02-06 05:00 | [PriorProbe: Recovering Individual-Level Priors for Personalizing Neural Networks in Facial Expression Recognition](https://arxiv.org/abs/2602.03882) | export.arxiv.org |
| 2026-02-06 05:00 | [Explainable Computer Vision Framework for Automated Pore Detection and Criticality Assessment in Additive Manufacturing](https://arxiv.org/abs/2602.03883) | export.arxiv.org |
| 2026-02-06 05:00 | [Sounding Highlights: Dual-Pathway Audio Encoders for Audio-Visual Video Highlight Detection](https://arxiv.org/abs/2602.03891) | export.arxiv.org |
| 2026-02-06 05:00 | [Signal or 'Noise': Human Reactions to Robot Errors in the Wild](https://arxiv.org/abs/2602.05010) | export.arxiv.org |
| 2026-02-06 05:00 | [Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping](https://arxiv.org/abs/2602.05029) | export.arxiv.org |
| 2026-02-06 05:00 | [Reinforcement Learning Enhancement Using Vector Semantic Representation and Symbolic Reasoning for Human-Centered Autonomous Emergency Braking](https://arxiv.org/abs/2602.05079) | export.arxiv.org |
| 2026-02-06 05:00 | [A Framework for Combining Optimization-Based and Analytic Inverse Kinematics](https://arxiv.org/abs/2602.05092) | export.arxiv.org |
| 2026-02-06 05:00 | [PLATO Hand: Shaping Contact Behavior with Fingernails for Precise Manipulation](https://arxiv.org/abs/2602.05156) | export.arxiv.org |
| 2026-02-06 05:00 | [Informative Path Planning with Guaranteed Estimation Uncertainty](https://arxiv.org/abs/2602.05198) | export.arxiv.org |
| 2026-02-06 05:00 | [MobileManiBench: Simplifying Model Verification for Mobile Manipulation](https://arxiv.org/abs/2602.05233) | export.arxiv.org |
| 2026-02-06 05:00 | [Low-Cost Underwater In-Pipe Centering and Inspection Using a Minimal-Sensing Robot](https://arxiv.org/abs/2602.05265) | export.arxiv.org |
| 2026-02-06 05:00 | [Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions](https://arxiv.org/abs/2602.05273) | export.arxiv.org |
| 2026-02-06 05:00 | [Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework](https://arxiv.org/abs/2602.05310) | export.arxiv.org |
| 2026-02-06 05:00 | [RoboPaint: From Human Demonstration to Any Robot and Any View](https://arxiv.org/abs/2602.05325) | export.arxiv.org |
| 2026-02-06 05:00 | [Benchmarking Affordance Generalization with BusyBox](https://arxiv.org/abs/2602.05441) | export.arxiv.org |
| 2026-02-06 05:00 | [Ontology-Driven Robotic Specification Synthesis](https://arxiv.org/abs/2602.05456) | export.arxiv.org |
| 2026-02-06 05:00 | [TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation](https://arxiv.org/abs/2602.05468) | export.arxiv.org |
| 2026-02-06 05:00 | [DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter](https://arxiv.org/abs/2602.05513) | export.arxiv.org |


## ‚≠ê GitHub TrendingÔºàDailyÔºåAI/Êú∫Âô®‰∫∫ËøáÊª§Ôºâ

| # | ‰ªìÂ∫ì | ÁÆÄ‰ªã |

|---:|---|---|

| 1 | [login?return_to=%2Fbytedance%2FUI-TARS-desktop" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:918932603,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/trending?since=daily&quot;,&quot;user_id&quot;:null}}](https://github.com/login?return_to=%2Fbytedance%2FUI-TARS-desktop" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:918932603,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/trending?since=daily&quot;,&quot;user_id&quot;:null}}) | Star


  

  
    
    


      
        bytedance /

      UI-TARS-desktop  

    
      The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra |


## ‚≠ê GitHub TrendingÔºàWeeklyÔºåAI/Êú∫Âô®‰∫∫ËøáÊª§Ôºâ

| # | ‰ªìÂ∫ì | ÁÆÄ‰ªã |

|---:|---|---|

| 1 | [sponsors/openclaw](https://github.com/sponsors/openclaw) | Sponsor
    
  



      
            
    

    

        
          Star


  

  
    
    


      
        openclaw /

      openclaw  

    
      Your own personal AI assistant. Any OS. Any Platform. The lobster way. ü¶û |
| 2 | [sponsors/thedotmack](https://github.com/sponsors/thedotmack) | Sponsor
    
  



      
            
    

    

        
          Star


  

  
    
    


      
        thedotmack /

      claude-mem  

    
      A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions. |
| 3 | [sponsors/badlogic](https://github.com/sponsors/badlogic) | Sponsor
    
  



      
            
    

    

        
          Star


  

  
    
    


      
        badlogic /

      pi-mono  

    
      AI agent toolkit: coding agent CLI, unified LLM API, TUI &amp; web UI libraries, Slack bot, vLLM pods |
| 4 | [sponsors/ThePrimeagen](https://github.com/sponsors/ThePrimeagen) | Sponsor
    
  



      
            
    

    

        
          Star


  

  
    
    


      
        ThePrimeagen /

      99  

    
      Neovim AI agent done right |
| 5 | [login?return_to=%2Fmicrosoft%2Fagent-lightning" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:1004147641,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/trending?since=weekly&quot;,&quot;user_id&quot;:null}}](https://github.com/login?return_to=%2Fmicrosoft%2Fagent-lightning" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:1004147641,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/trending?since=weekly&quot;,&quot;user_id&quot;:null}}) | Star


  

  
    
    


      
        microsoft /

      agent-lightning  

    
      The absolute trainer to light up AI agents. |
| 6 | [login?return_to=%2FNevaMind-AI%2FmemU" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:1028070615,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/trending?since=weekly&quot;,&quot;user_id&quot;:null}}](https://github.com/login?return_to=%2FNevaMind-AI%2FmemU" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:1028070615,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/trending?since=weekly&quot;,&quot;user_id&quot;:null}}) | Star


  

  
    
    


      
        NevaMind-AI /

      memU  

    
      Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot). |


_Ëá™Âä®ÁîüÊàê ¬∑ ÈÖçÁΩÆ‰∏éËÑöÊú¨ËßÅ `ai_robotics_daily.py`„ÄÇ_
